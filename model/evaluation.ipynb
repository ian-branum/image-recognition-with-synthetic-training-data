{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "#!apt-get update\n",
    "#!python3 -m pip install --upgrade pip\n",
    "#!pip install opencv-python\n",
    "#!apt-get install -y libglib2.0-0\n",
    "#!apt-get install -y libsm6 libxext6 libxrender-dev\n",
    "#!pip install matplotlib --upgrade\n",
    "#!apt-get install -y python3-skimage\n",
    "#!pip install scikit-image==0.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/image-recognition-with-synthetic-training-data/model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\".\")\n",
    "print(ROOT_DIR)\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, 'models')\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, 'models/mask_rcnn_coco.h5')\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehiclesConfig(Config):\n",
    "    NAME = \"vehicles\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 4\n",
    "    NUM_CLASSES = 1 + 2  # background + 2 shapes\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "    #BACKBONE = \"resnet50\" -- default is resnet101\n",
    "\n",
    "    #These are for BW\n",
    "    #IMAGE_CHANNEL_COUNT = 1\n",
    "    #MEAN_PIXEL = 1\n",
    "    \n",
    "    #Faster epochs?\n",
    "    #STEPS_PER_EPOCH = 100\n",
    "config = VehiclesConfig()\n",
    "#config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class\n",
    "\n",
    "Here we create a class that overrides utils.Dataset. Must override the following methods:\n",
    "\n",
    "* load_images() -- this loads images from files into the Dataset object\n",
    "* load_mask() -- this returns the mask for the identified image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehiclesDataset(utils.Dataset):\n",
    "    '''\n",
    "    This provides tools to load the training images/masks and encapsulates them for the model\n",
    "    '''\n",
    "    def load_images(self, dataset_dir, proportion=1.0):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.add_class('vehicles', 1, 'car')\n",
    "        self.add_class('vehicles', 2, 'pickup')\n",
    "        for filename in os.listdir(dataset_dir):\n",
    "            if(os.path.isdir(dataset_dir + '\\\\' + filename)):\n",
    "                continue\n",
    "            image_path = os.path.join(dataset_dir, filename)\n",
    "            if(random.random() < proportion):            \n",
    "                self.add_image(\n",
    "                    \"vehicles\",\n",
    "                    image_id=filename,  \n",
    "                    path=image_path,\n",
    "                    width=256, \n",
    "                    height=256\n",
    "            )\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        '''\n",
    "        Return the mask for the id'd image\n",
    "        '''\n",
    "        id = self.image_info[image_id]['id']\n",
    "        car_id = id.split('_')[2]\n",
    "        cam_id = id.split('_')[4]\n",
    "        shot_id = id.split('_')[5]\n",
    "        mask_id = '{0}_{1}_{2}'.format(car_id, cam_id, shot_id)\n",
    "        mask = Image.open(mask_dir + mask_id)\n",
    "        if('car' in car_id):\n",
    "            class_id = 1\n",
    "        else:\n",
    "            class_id = 2\n",
    "        mask_as_array = np.expand_dims(np.array(mask), axis=2)\n",
    "        return mask_as_array*1, np.array([class_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_dir = '../../data/color/train'\n",
    "val_dataset_dir = '../../data/color/val'\n",
    "mask_dir = '../../data/masks/'\n",
    "\n",
    "\n",
    "# Training dataset\n",
    "dataset_train = VehiclesDataset()\n",
    "dataset_train.load_images(train_dataset_dir)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = VehiclesDataset()\n",
    "dataset_val.load_images(val_dataset_dir)\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from  /root/image-recognition-with-synthetic-training-data/model/models/mask_rcnn_vehicles-clean-start-10.h5\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(VehiclesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "#model_path = os.path.join(MODEL_DIR, \"mask_rcnn_vehicles25.h5\")\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_vehicles-clean-start-10.h5\")\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP:  0.918\n"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 1000)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_train, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_test(directory='../../data/test/'):\n",
    "    preds = []\n",
    "    #axs = get_ax(118, 1, 12)\n",
    "    for i, filename in enumerate(os.listdir(directory)):\n",
    "        #print(filename)\n",
    "        if(os.path.isdir(directory + '/' + filename)):\n",
    "            continue\n",
    "        img = Image.open(directory + '/' + filename)\n",
    "        img = img.resize((256, 256))\n",
    "        img_as_arr = np.array(img)\n",
    "        results = model.detect([img_as_arr], verbose=0)\n",
    "        if(len(results[0]['class_ids']) > 0):\n",
    "            class_id = results[0]['class_ids'][0]\n",
    "            score = results[0]['scores'][0]\n",
    "            if('car' in filename):\n",
    "                actual_class = 1\n",
    "            elif('pickup' in filename):\n",
    "                actual_class = 2\n",
    "            else:\n",
    "                actual_class = 0\n",
    "            preds.append([filename, actual_class, class_id, float(score)])\n",
    "            #preds.append('file: {0}, predicted class: {1}, score: {2}'.format(filename, class_id, score))\n",
    "        else:\n",
    "            preds.append([filename, actual_class, 0, 0])\n",
    "    return preds\n",
    "preds_new2 = score_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  7,  1],\n",
       "       [ 3, 36, 11],\n",
       "       [ 3, 42,  5]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(preds_new2)\n",
    "confusion_matrix(df[1], df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.11      0.12         9\n",
      "           1       0.42      0.72      0.53        50\n",
      "           2       0.29      0.10      0.15        50\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       109\n",
      "   macro avg       0.29      0.31      0.27       109\n",
      "weighted avg       0.34      0.39      0.32       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[1], df[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['car-19.png', 1, 1, 0.738649308681488],\n",
       " ['pickup-13.png', 2, 2, 0.9595611095428467],\n",
       " ['car-37.png', 2, 0, 0],\n",
       " ['pickup-31.png', 2, 2, 0.9910202622413635],\n",
       " ['car-28.png', 1, 1, 0.8691062927246094],\n",
       " ['pickup-22.png', 2, 2, 0.9533739686012268],\n",
       " ['car-46.png', 1, 1, 0.9484565854072571],\n",
       " ['pickup-40.png', 2, 2, 0.9843562245368958],\n",
       " ['pickup-4.png', 2, 2, 0.992992639541626],\n",
       " ['car-20.png', 1, 2, 0.8867312669754028],\n",
       " ['car-2.png', 1, 0, 0],\n",
       " ['pickup-39.png', 2, 2, 0.99094557762146],\n",
       " ['car-11.png', 1, 1, 0.8293371200561523],\n",
       " ['nada-4.png', 1, 0, 0],\n",
       " ['pickup-48.png', 2, 2, 0.9918733239173889],\n",
       " ['pickup-17.png', 2, 2, 0.9879947304725647],\n",
       " ['pickup-35.png', 2, 2, 0.9901829361915588],\n",
       " ['pickup-26.png', 2, 2, 0.99076908826828],\n",
       " ['nada-0.png', 0, 1, 0.8758792877197266],\n",
       " ['pickup-8.png', 2, 2, 0.9881957769393921],\n",
       " ['pickup-44.png', 2, 2, 0.9934331178665161],\n",
       " ['car-24.png', 1, 1, 0.8773436546325684],\n",
       " ['car-6.png', 1, 2, 0.8114509582519531],\n",
       " ['car-42.png', 1, 2, 0.9627588987350464],\n",
       " ['pickup-0.png', 2, 2, 0.9368981122970581],\n",
       " ['car-33.png', 2, 0, 0],\n",
       " ['car-15.png', 1, 1, 0.7973619103431702],\n",
       " ['nada-8.png', 1, 0, 0],\n",
       " ['pickup-15.png', 2, 2, 0.9895309209823608],\n",
       " ['pickup-33.png', 2, 2, 0.979805052280426],\n",
       " ['car-39.png', 1, 1, 0.900394856929779],\n",
       " ['pickup-24.png', 2, 2, 0.967012345790863],\n",
       " ['pickup-42.png', 2, 2, 0.9949367046356201],\n",
       " ['pickup-6.png', 2, 2, 0.9808498024940491],\n",
       " ['car-48.png', 1, 2, 0.9237120747566223],\n",
       " ['car-4.png', 1, 2, 0.954048216342926],\n",
       " ['car-22.png', 1, 2, 0.7594168186187744],\n",
       " ['car-40.png', 1, 2, 0.8579818606376648],\n",
       " ['car-31.png', 1, 1, 0.9444065690040588],\n",
       " ['car-13.png', 1, 0, 0],\n",
       " ['nada-6.png', 0, 1, 0.8014756441116333],\n",
       " ['car-0.png', 0, 0, 0],\n",
       " ['pickup-19.png', 2, 2, 0.9832441210746765],\n",
       " ['pickup-37.png', 2, 2, 0.9890338182449341],\n",
       " ['pickup-28.png', 2, 2, 0.9899410605430603],\n",
       " ['pickup-46.png', 2, 2, 0.9919934272766113],\n",
       " ['nada-2.png', 0, 2, 0.9035629630088806],\n",
       " ['car-8.png', 1, 2, 0.8929352760314941],\n",
       " ['pickup-20.png', 2, 2, 0.9950070381164551],\n",
       " ['car-26.png', 2, 0, 0],\n",
       " ['pickup-2.png', 2, 2, 0.9928245544433594],\n",
       " ['car-44.png', 2, 0, 0],\n",
       " ['car-35.png', 1, 1, 0.9770292639732361],\n",
       " ['pickup-11.png', 2, 2, 0.9927339553833008],\n",
       " ['car-17.png', 1, 2, 0.868683934211731],\n",
       " ['pickup-14.png', 2, 2, 0.9930307269096375],\n",
       " ['pickup-32.png', 2, 2, 0.9876984357833862],\n",
       " ['car-38.png', 2, 0, 0],\n",
       " ['pickup-23.png', 2, 2, 0.9977859258651733],\n",
       " ['car-29.png', 2, 0, 0],\n",
       " ['pickup-41.png', 2, 2, 0.9921060800552368],\n",
       " ['pickup-5.png', 2, 2, 0.9773513078689575],\n",
       " ['car-47.png', 1, 2, 0.8352621793746948],\n",
       " ['car-3.png', 1, 0, 0],\n",
       " ['car-21.png', 1, 2, 0.9068126082420349],\n",
       " ['car-30.png', 1, 0, 0],\n",
       " ['pickup-49.png', 2, 2, 0.9855374693870544],\n",
       " ['nada-5.png', 2, 0, 0],\n",
       " ['car-12.png', 1, 1, 0.8092017769813538],\n",
       " ['nada-10.png', 1, 0, 0],\n",
       " ['pickup-18.png', 2, 2, 0.9936571717262268],\n",
       " ['pickup-36.png', 2, 2, 0.9910029172897339],\n",
       " ['pickup-27.png', 2, 2, 0.9938376545906067],\n",
       " ['pickup-45.png', 2, 2, 0.9887219667434692],\n",
       " ['pickup-9.png', 2, 2, 0.9953836798667908],\n",
       " ['car-7.png', 1, 2, 0.7724971771240234],\n",
       " ['car-25.png', 1, 1, 0.8497766852378845],\n",
       " ['pickup-1.png', 2, 2, 0.9882517457008362],\n",
       " ['car-43.png', 1, 1, 0.8394750356674194],\n",
       " ['car-34.png', 1, 1, 0.9614441394805908],\n",
       " ['nada-9.png', 0, 2, 0.7043742537498474],\n",
       " ['car-16.png', 1, 1, 0.7330968379974365],\n",
       " ['pickup-10.png', 2, 2, 0.9912398457527161],\n",
       " ['pickup-16.png', 2, 2, 0.9910633563995361],\n",
       " ['pickup-34.png', 2, 2, 0.9642190337181091],\n",
       " ['pickup-25.png', 2, 2, 0.9923219084739685],\n",
       " ['pickup-7.png', 2, 2, 0.9663680195808411],\n",
       " ['pickup-43.png', 2, 2, 0.991496205329895],\n",
       " ['car-23.png', 1, 2, 0.8596571087837219],\n",
       " ['car-5.png', 1, 0, 0],\n",
       " ['car-41.png', 1, 2, 0.9697420597076416],\n",
       " ['car-32.png', 1, 1, 0.7959959506988525],\n",
       " ['nada-7.png', 0, 2, 0.9180871248245239],\n",
       " ['car-14.png', 1, 1, 0.9117761850357056],\n",
       " ['car-1.png', 1, 0, 0],\n",
       " ['pickup-38.png', 2, 2, 0.9868953824043274],\n",
       " ['pickup-29.png', 2, 2, 0.9945758581161499],\n",
       " ['nada-3.png', 2, 0, 0],\n",
       " ['pickup-47.png', 2, 2, 0.9850689768791199],\n",
       " ['car-10.png', 1, 2, 0.8254555463790894],\n",
       " ['car-27.png', 1, 2, 0.8028002381324768],\n",
       " ['car-9.png', 1, 2, 0.8190281391143799],\n",
       " ['pickup-21.png', 2, 2, 0.9940179586410522],\n",
       " ['car-45.png', 1, 1, 0.7036486268043518],\n",
       " ['pickup-3.png', 2, 2, 0.9362444281578064],\n",
       " ['car-36.png', 2, 0, 0],\n",
       " ['pickup-30.png', 2, 2, 0.9935157299041748],\n",
       " ['pickup-12.png', 2, 2, 0.9939523339271545],\n",
       " ['car-18.png', 1, 2, 0.9071221947669983]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-1.15-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
